{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNasdSYlzS70tM0AUopYVct",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagarishere/DockerGettingStarted/blob/main/DockerTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>What is containerisation?</center>\n",
        "\n",
        "<div align=\"justify\">\n",
        "\n",
        "Containerisation is making the copy of the files needed to be run by the os, in an isolated root via namespace. \n",
        "\n",
        "In simplistic terms, Containerisation provides a way to isolate the environment that is needed to run our application from the rest of the operating system.\n",
        "</div>"
      ],
      "metadata": {
        "id": "14facOGd04YL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"justify\">\n",
        "\n",
        "Because a container runs inside the namespace isolated root directories inside the OS, a few nuances are resultant:\n",
        "\n",
        "1. **Not negotiable**: They have to run on a single host (contained inside a namespaced isolated root). So two computers cannot run a single container (with micro-kernel based OS architecture this might be possible but that's for another day).\n",
        "\n",
        "2. **Packaging**: They are groups of processes. You might know that Linux processes live inside a tree structure, so we can say containers must have a root process. In practise, this means we have to make an image package of the files we need to run those processes we want to make an isolated enviornment.\n",
        "\n",
        "3. **Isolation**: They need to be isolated. In practise it means that the namespace seperation from the OS needs to be implemented, so that any program running inside this custom root dir cannot access any process/dir in the main OS on which the docker container is hosted.\n",
        "\n",
        "4. **Fulfill features requirements**: They have to fulfill common features required by the Applications we run in the container. Features in general seem to change over time, so we have to point out what the most common features are and update our image accordingly.<br> \n",
        "\n",
        "There are two approaches to feature fulfillment (expanding the fourth point above):\n",
        "- A) **Feature light**: One is to go container heavy by having un-needed features in the image, another is to go light, and add files as and when needed to support the newly added Application features if required.\n",
        "In essense we take the minimum required, and is good for deployement.<br> \n",
        "- B) **Feature loaded**: An example of the second approach would be to start with the Apline Linux as a base image. An example of the first approach could be using Ubuntu as a base image.\n",
        "In essense we take as much as we can so we can do faster development. This is not good for deployement and stripping or rebasing should be done on lighter base image for delployement.\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6jnKhkcG1Zch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<center>What is Docker?</center>\n",
        "<p align=\"justify\">\n",
        "Docker is the most used auto-containerisation system. Docker runs over macro kernel systems like Unix-like Mac, Linus, or Windows OS. Docker containerisation takes advantage of the namespace and chroot features of the OS. We could do the processes involve manually but Docker provides an easier way (abstraction commands) where we are able to execute a lot of underlying system level commands needed by executing simple set of commands using the docker library.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "of6PQxMBz32-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>What is DockerHub?\n",
        "\n",
        "<div align=\"justify\">\n",
        "\n",
        "Dockerhub is a repository website where one can push and pull our cutom images.<br><br> An image is actually an image-set made of many different images, however, technically the lowest you can go over an image is a base-image.<br> You could think of an image as a painting with base image being the canvas.\n",
        "\n",
        "When we download/pull an image from the Docer-hub, it checks though all the sub-set of images that the image-set is made of, and only downlods those layers/sub-sets of images from the docker-hub that have not already been downloaded to the local repo/warehouse that our local Docker Application refers to.<br><br> By this method of downloading only the sub-set that is different, there are 2 advantages. 1. It saves the bandwidth 2. Concurrent downloading of various layers/sub-sets becomes possible.\n",
        "</div>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HkXr-Kh8_Ei7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>What are the advantages of using containers?\n",
        "\n",
        "<div align=\"justify\">\n",
        "\n",
        "Advantages of using containers are the following:\n",
        "1. Batteries included application: The application that we ship inside the organisation between one developer to another or one department to another requires no configuration. All configuration and dependencies are included within the Docker container.\n",
        "2. OS poisoning avoided: The base OS if is used by the developer for installing non-compatible dependencies would be poisoned and is a bad practise, also frustrating.\n",
        "3. Less resources: Compared to Virtual Machine, the containers do not run a whole OS, but only the sub-set that is required to namespace chroot and dependencies of the application. So resources of the underlying OS are free and only used on need basis. Hardware level isolation of resources does not happen, hence system resources are more effeciently utilised.\n",
        "</div><br>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kdRxd3LQBBk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<center>Magnifying on a docker command:</center>\n",
        "<br>\n",
        "<div align=\"justify\">\n",
        "\n",
        "```bash\n",
        "docker run -dp 80:80 docker/getting-started\n",
        "```\n",
        "\n",
        "\n",
        "The `docker` keyword calls for the docker library to accept the arguments that follow to be processed by the docker library. Think of this as a piping function to the Docker application installed on your OS.\n",
        "<br><br>\n",
        "The command `run` when received by the Docker application, expects that you will now supply an image-name to run. <br>\n",
        "In this case, we put the image name as `docker/getting-started`.\n",
        "<br><br>\n",
        "If this image is on the local computer, then it will be run. If it is not on the local computer, the Docker application will contact the docker-hub to look for this image name. If this image-name will be found on the docker-hub, this image will be downloaded from there and run. If this image is not found on the local computer as well as on the Docker-hub, it will tell you that image does not exist or image not found. <br><br>\n",
        "You will notice that in the above command, we made use of `-dp 80:80`. The image can be run by docker in two different modes: \n",
        "1. *Interactive mode*: here we will have to write the flag `-i` and we will get docker terminal as soon as docker starts running. As we can interact with the docker enviornment immideately through the terminal, this is called interactive mode.\n",
        "2. *Detached mode*: here we will have to write the flag `-d` (as in the above command). With this flag we will continue to use the host OS terminal that we are using and the docker terminal does not become available to us automatically. So, we can say that the docker is running in the background.\n",
        "\n",
        "<br>\n",
        "\n",
        "Final mystery: what is `-p` in the command, and what is `80:80`?\n",
        "<br>\n",
        "`-p` is flag for port. `-p` opens up a port on the isolated root (container) to connect to the local locahine root (underlying OS port). So here in `80:80`, the first 80 is the number of th port that has been opened in the container. The second 80 is the number of the port on the local machine that the container's port 80 has now been connected to.<br>\n",
        "\n",
        "With use of the full command, we run the container of an image named docker/getting-started in the background and connect it's port 80 to the port 80 of the local machine.<br>\n",
        "If you will open [http://localhost]() , you will be able to go open the Getting Started Docker Tutorial on your local machine. \n",
        "</div>\n",
        "<br>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "LiJ5w6o6Dsmq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uzP9nRITIVps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}